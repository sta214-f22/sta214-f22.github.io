---
title: Inference and overdispersion 
output:
  xaringan::moon_reader:
    css: "lab-slides.css"
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

### Last time: modeling article publication

```{r include=F}
library(knitr)
library(tidyverse)
library(MASS)

crimes <- read_csv("~/Documents/Teaching/sta214-f22.github.io/slides/c_data.csv")

hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
   lines <- options$output.lines
   if (is.null(lines)) {
     return(hook_output(x, options))  # pass to default hook
   }
   x <- unlist(strsplit(x, "\n"))
   more <- "..."
   if (length(lines)==1) {        # first n lines
     if (length(x) > lines) {
       # truncate the output, but add ....
       x <- c(head(x, lines), more)
     }
   } else {
     x <- c(more, x[lines], more)
   }
   # paste these lines together
   x <- paste(c(x, ""), collapse = "\n")
   hook_output(x, options)
 })

m1 <- glm(nv ~ region, offset = log(enroll1000),
          data = crimes, family = poisson)
```

.large[
We are interested in analyzing the number of articles published by biochemistry PhD students. The data contains the following variables:

* `art`: articles published in last three years of Ph.D.
* `fem`: gender (recorded as male or female)
* `mar`: marital status (recorded as married or single)
* `kid5`: number of children under age six
* `phd`: prestige of Ph.D. program
* `ment`: articles published by their mentor in last three years

$$Articles_i \sim Poisson(\lambda_i)$$
$$\log(\lambda_i) = \beta_0 + \beta_1 Female_i + \beta_2 Married_i + \beta_3 Kids_i + \\  \beta_4 Prestige_i + \beta_5 Mentor_i$$
]

---

### Checking mean vs. variance

```{r, echo=F, message=F, warning=F}
library(foreign)

articles <- read.dta("http://www.stata-press.com/data/lf2/couart2.dta")

m1 <- glm(art ~ ., data = articles, family = poisson)
```

.large[
```{r}
mean(articles$art)
var(articles$art)
```
]

---

### Overdispersion

.large[
**Overdispersion** occurs when the response $Y$ has higher variance than we would expect if $Y$ followed a Poisson distribution.

.question[
What problems do you think it causes to assume the mean and variance are the same, when they are not?
]
]

---

### Formal checks for overdispersion

.large[
First, we need a formal measure of dispersion (relation between mean and variance):

$$\phi = \dfrac{\text{Variance}}{\text{Mean}}$$

.question[
What should $\phi$ be if there is no overdispersion?
]
]

---

### Hypothesis test for overdispersion

.large[
$$\phi = \dfrac{\text{Variance}}{\text{Mean}}$$

$H_0: \phi = 1$ (no overdispersion)

$H_A: \phi > 1$ (overdispersion)

Now we need to estimate $\phi$...
]

---

### Pearson residuals and estimated dispersion

.large[
The *Pearson residual* for observation $i$ is defined as

$$e_{(P)i} = \dfrac{Y_i - \widehat{\lambda}_i}{\sqrt{\widehat{\lambda}_i}}$$
]

</br>

.large[
$$\widehat{\phi} = \dfrac{\sum \limits_{i=1}^n e_{(P)i}^2}{n - p}$$

* $p =$ number of parameters in model
]

---

### Example: estimating dispersion parameter in R

.large[
```{r}
# fit the model
m1 <- glm(art ~ ., data = articles, 
          family = poisson)

# get Pearson residuals
pearson_resids <- resid(m1, "pearson")

# estimate dispersion parameter
phihat <- sum(pearson_resids^2)/(915 - 6)
phihat
```
]

---

### Back to the hypothesis test

.large[
$$\phi = \dfrac{\text{Variance}}{\text{Mean}}$$

$H_0: \phi = 1$ (no overdispersion)

$H_A: \phi > 1$ (overdispersion)

$\widehat{\phi} = 1.829$

.question[
Now what?
]
]

---

### Calculating a p-value

.large[

```{r, message=F, warning=F}
library(AER)
dispersiontest(m1)
```

So there is strong evidence for overdispersion in the data.
]

---

### Handling overdispersion

.large[
Overdispersion is a problem because our standard errors (for confidence intervals and hypothesis tests) are too low.

.question[
If we think there is overdispersion, what should we do?
]
]

---

### Adjusting the standard error

.large[
* In our data, $\widehat{\phi} = 1.829$
* This means our variance is 1.829 times bigger than it should be
* So our standard error is $\sqrt{1.829} = 1.352$ times bigger than it should be

New confidence interval for $\beta_4$:

$0.0128 \pm 1.96 \cdot \sqrt{1.829} \cdot 0.0264 = (-0.0572, \ 0.0828)$
]

---

### Adjusting the standard error in R

.large[
```{r, message=F, warning=F}
m2 <- glm(art ~ ., data = articles, 
          family = quasipoisson)
```
]

```{r echo=F, output.lines = 10:20}
summary(m2)
```

.large[
* Allowing $\phi$ to be different from 1 means we are using a *quasi-likelihood* (in this case, a *quasi-Poisson*)
]

---

### Adjusting the standard error in R

.large[
**Poisson:**

```{r echo=F, output.lines = 10:14}
summary(m1)
```

**Quasi-Poisson:**

```{r echo=F, output.lines = 10:14}
summary(m2)
```
]

---

### Class activity

.large[
```{r echo=F, message=F, warning=F, output.lines=10:17}
crimes <- read_csv("~/Documents/Teaching/sta279-s22.github.io/slides/c_data.csv")

m2 <- glm(nv ~ region, offset = log(enroll1000),
          data = crimes, family = quasipoisson)
summary(m2)
```

.question[
What confidence interval should I calculate to compare western and central schools?
]
]

---

### Class activity

.large[
```{r echo=F, message=F, warning=F, output.lines=10:17}
crimes <- read_csv("~/Documents/Teaching/sta279-s22.github.io/slides/c_data.csv")

m2 <- glm(nv ~ region, offset = log(enroll1000),
          data = crimes, family = quasipoisson)
summary(m2)
```

95% confidence interval for $\beta_5$: 

$0.209 \pm 1.96 \cdot 0.512 = (-0.795, \ 1.213)$

95% confidence interval for $e^{\beta_5}$:

$(e^{-0.795}, e^{1.213}) = (0.452, \ 3.364)$
]

---

### Comparing Poisson and quasi-Poisson

.large[
**Poisson:**

* Mean = $\lambda_i$
* Variance = $\lambda_i$

**quasi-Poisson:**

* Mean = $\lambda_i$
* Variance = $\phi \lambda_i$
* Variance is a linear function of the mean

.question[
What if we want variance to depend on the mean in a different way?
]
]

---

### Introducing the negative binomial

.large[
If $Y_i \sim NB(\theta, p)$, then $Y_i$ takes values $y = 0, 1, 2, 3, ...$ with probabilities

$$P(Y_i = y) = \dfrac{(y + \theta - 1)!}{y!(\theta - 1)!} (1 - p)^\theta p^y$$

* $\theta > 0$, $\ \ \ p \in [0, 1]$
* Mean = $\dfrac{p \theta}{1 - p} = \mu$
* Variance = $\dfrac{p \theta}{(1 - p)^2} = \mu + \dfrac{\mu^2}{\theta}$
* Variance is a *quadratic* function of the mean
]

---

### Mean and variance for a negative binomial variable

.large[
If $Y_i \sim NB(\theta, p)$, then

* Mean = $\dfrac{p \theta}{1 - p} = \mu$
* Variance = $\dfrac{p \theta}{(1 - p)^2} = \mu + \dfrac{\mu^2}{\theta}$

.question[
How is $\theta$ related to overdispersion?
]
]

---

### Negative binomial regression

.large[
$$Y_i \sim NB(\theta, \ p_i)$$

$$\log(\mu_i) = \beta_0 + \beta_1 X_i$$

* $\mu_i = \dfrac{p_i \theta}{1 - p_i}$
* Note that $\theta$ is the same for all $i$
* Note that just like in Poisson regression, we model the average count
  * Interpretation of $\beta$s is the same as in Poisson regression
]

---

### Comparing Poisson, quasi-Poisson, negative binomial

.large[
**Poisson:**

* Mean = $\lambda_i$
* Variance = $\lambda_i$

**quasi-Poisson:**

* Mean = $\lambda_i$
* Variance = $\phi \lambda_i$

**negative binomial:**

* Mean = $\mu_i$
* Variance = $\mu_i + \dfrac{\mu_i^2}{\theta}$
]

---

### In R

.large[
```{r message=F}
m3 <- glm.nb(art ~ ., data = articles)
```

```{r echo=F, output.lines = 11:21}
summary(m3)
```

$\widehat{\theta} = 2.264$
]

---

### In R

.large[
```{r echo=F, output.lines = 11:17}
summary(m3)
```

.question[
How do I interpret the estimated coefficient -0.176?
]
]


---

### quasi-Poisson vs. negative binomial

.large[

.pull-left[
**quasi-Poisson:**

* linear relationship between mean and variance
* easy to interpret $\widehat{\phi}$
* same as Poisson regression when $\phi = 1$
* simple adjustment to estimated standard errors
* estimated coefficients same as in Poisson regression
]

.pull-right[
**negative binomial:**

* quadratic relationship between mean and variance
* we get to use a likelihood, rather than a quasi-likelihood
* Same as Poisson regression when $\theta$ is very large and $p$ is very small
]

.question[
For this class, either is appropriate to handle overdispersion.
]
]