---
title: Beginning linear mixed effects models
output:
  xaringan::moon_reader:
    css: "lab-slides.css"
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

### Data: flipped classrooms?

.large[
Data set has 375 rows (one per student), and the following variables:

* `professor`: which professor taught the class (1 -- 15)
* `style`: which teaching style the professor used (no flip, some flip, fully flipped)
* `score`: the student's score on the final exam
]

---

### Visualizing the data

```{r echo=F, message=F, warning=F, fig.width=9, fig.height=6, fig.align='center'}

library(tidyverse)
library(knitr)

hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
   lines <- options$output.lines
   if (is.null(lines)) {
     return(hook_output(x, options))  # pass to default hook
   }
   x <- unlist(strsplit(x, "\n"))
   more <- "..."
   if (length(lines)==1) {        # first n lines
     if (length(x) > lines) {
       # truncate the output, but add ....
       x <- c(head(x, lines), more)
     }
   } else {
     x <- c(more, x[lines], more)
   }
   # paste these lines together
   x <- paste(c(x, ""), collapse = "\n")
   hook_output(x, options)
 })

set.seed(3)

mean_scores <- c(84, 78, 76, 82, 83,
                     82, 80, 90, 91, 87,
                     79, 80, 83, 82, 85)

diffs <- mean_scores - rep(c(80, 87, 83), each=5)

mean_scores <- rep(c(80, 87, 83), each=5) + 0.5*diffs

data.frame(professor = rep(1:15, each=25),
           style = factor(rep(c("no flip", "some flip", "full flip"),
                                 each=125),
                             levels = c("no flip", "some flip", "full flip"))) %>%
  mutate(score = rnorm(375, mean = mean_scores[professor], sd = 2),
         professor = rep(rep(1:5, each=25), 3)) %>%
  ggplot(aes(x = as.factor(professor), y = score)) +
  geom_boxplot(lwd=1) +
  facet_wrap(~style) +
  labs(x = "Professor", y = "Score") +
  theme_classic() +
  theme(text = element_text(size = 30),
        axis.text.x=element_blank(),
        axis.text.y = element_text(size=20))
```

---

### Mixed effects model

.large[
**Linear mixed effects model:** Let $Score_{ij}$ be the score of student $j$ in class $i$

\begin{align}
Score_{ij} &= \beta_0 + \beta_1 \text{SomeFlipped}_i + \beta_2 \text{FullyFlipped}_i + u_i + \varepsilon_{ij}
\end{align}

$\varepsilon_{ij} \overset{iid}{\sim} N(0, \sigma_\varepsilon^2) \hspace{1cm} u_i \overset{iid}{\sim} N(0, \sigma_u^2)$
]

.large[
.question[
Which terms are the fixed effects?
]
]

---

### Mixed effects model

.large[
**Linear mixed effects model:** Let $Score_{ij}$ be the score of student $j$ in class $i$

\begin{align}
Score_{ij} &= \beta_0 + \beta_1 \text{SomeFlipped}_i + \beta_2 \text{FullyFlipped}_i + u_i + \varepsilon_{ij}
\end{align}

$\varepsilon_{ij} \overset{iid}{\sim} N(0, \sigma_\varepsilon^2) \hspace{1cm} u_i \overset{iid}{\sim} N(0, \sigma_u^2)$
]

.large[
.question[
Which term is the random effect?
]
]

---

### Mixed effects model

.large[
**Linear mixed effects model:** Let $Score_{ij}$ be the score of student $j$ in class $i$

\begin{align}
Score_{ij} &= \beta_0 + \beta_1 \text{SomeFlipped}_i + \beta_2 \text{FullyFlipped}_i + u_i + \varepsilon_{ij}
\end{align}

$\varepsilon_{ij} \overset{iid}{\sim} N(0, \sigma_\varepsilon^2) \hspace{1cm} u_i \overset{iid}{\sim} N(0, \sigma_u^2)$
]

.large[
.question[
Which term captures variability between students?
]
]

---

### Class activity, Part I

.large[
[https://sta214-f22.github.io/class_activities/ca_lecture_26.html](https://sta214-f22.github.io/class_activities/ca_lecture_26.html)
]

---

### Class activity

.large[
.question[
Why is a mixed effect model useful for this data?
]
]

---

### Class activity

.large[
.question[
What is the population model?
]
]

---

### Class activity

.large[
.question[
What is the population model?
]
]

.large[
$$Price_{ij} = \beta_0 + \beta_1 Satisfaction_{ij} + u_i + \varepsilon_{ij}$$
$u_i \overset{iid}{\sim} N(0, \sigma_u^2) \hspace{1cm} \varepsilon_{ij} \overset{iid}{\sim} N(0, \sigma_\varepsilon^2)$

where $Price_{ij}$ is the price of rental $j$ in neighborhood $i$

* $u_i$ is a *random intercept*
* We use subscripts $i$ and $j$ for $Price_{ij}$, $Satisfaction_{ij}$, and $\varepsilon_{ij}$ because they are different for every observation in the data
* We only need a subscript $i$ (neighborhood) for $u_i$, because there is one random intercept per neighborhood
]

---

### Class activity

.large[
$$Price_{ij} = \beta_0 + \beta_1 Satisfaction_{ij} + u_i + \varepsilon_{ij}$$
$u_i \overset{iid}{\sim} N(0, \sigma_u^2) \hspace{1cm} \varepsilon_{ij} \overset{iid}{\sim} N(0, \sigma_\varepsilon^2)$

where $Price_{ij}$ is the price of rental $j$ in neighborhood $i$
]

.large[
.question[
What are the effect of interest, group effect, and individual effect?
]
]

---

### Class activity

.large[
$$Price_{ij} = \beta_0 + \beta_1 Satisfaction_{ij} + u_i + \varepsilon_{ij}$$
$u_i \overset{iid}{\sim} N(0, \sigma_u^2) \hspace{1cm} \varepsilon_{ij} \overset{iid}{\sim} N(0, \sigma_\varepsilon^2)$

where $Price_{ij}$ is the price of rental $j$ in neighborhood $i$
]

.large[
.question[
What are the effect of interest, group effect, and individual effect?
]
]

.large[
* effect of interest: $\beta_1$ (slope for relationship between satisfaction and price)
* group effect: $u_i$ (random effect for neighborhood)
* individual effect: $\varepsilon_{ij}$ (variation between rentals in a neighborhood)
]

---

### Fitting mixed effects models

.large[
```{r eval=F}
library(lme4)
m1 <- lmer(score ~ style + (1|professor), 
           data = teaching)
summary(m1)
```

* `lme4` is the R package we will use to fit mixed effects models
* `lmer` is like the `lm` function, but for mixed effects
* `style` is the teaching style (fixed effects)
* `(1|professor)` indicates we have a random intercept (the `1` indicates the intercept) for `professor` (indicated by `|professor` )
]

---

### Fitting mixed effects models

.large[
```{r, include=F}
set.seed(3)
mean_scores <- c(rnorm(5, 80, 6), rnorm(5, 87, 6), rnorm(5, 83, 6))

teaching <- data.frame(professor = rep(1:15, each=25),
           style = factor(rep(c("no flip", "some flip", "full flip"),
                                 each=125),
                             levels = c("no flip", "some flip", "full flip"))) %>%
  mutate(score = rnorm(375, mean = mean_scores[professor], sd = 2),
         professor = as.factor(professor))
```

```{r message=F}
library(lme4)
```

```{r, output.lines = 11:14}
m1 <- lmer(score ~ style + (1|professor), 
           data = teaching)
summary(m1)
```

* $\widehat{\sigma}_\varepsilon^2 = 4.25$
* $\widehat{\sigma}_u^2 = 21.37$
]

---

### Fitting mixed effects models

.large[

```{r, output.lines = 17:21}
m1 <- lmer(score ~ style + (1|professor), 
           data = teaching)
summary(m1)
```

* $\widehat{\beta}_0 = 77.66$
* $\widehat{\beta}_1 = 11.07$
* $\widehat{\beta}_2 = 2.81$
]

---

### Interpretation

.large[
\begin{align}
Score_{ij} &= \beta_0 + \beta_1 \text{SomeFlipped}_i + \beta_2 \text{FullyFlipped}_i + u_i + \varepsilon_{ij}
\end{align}

$\varepsilon_{ij} \overset{iid}{\sim} N(0, \sigma_\varepsilon^2) \hspace{1cm} u_i \overset{iid}{\sim} N(0, \sigma_u^2)$
]

.large[
* $\widehat{\beta}_0 = 77.66$, $\hspace{1cm} \widehat{\beta}_1 = 11.07$, $\hspace{1cm} \widehat{\beta}_2 = 2.81$
* $\widehat{\sigma}_\varepsilon^2 = 4.25$, $\hspace{1cm} \widehat{\sigma}_u^2 = 21.37$

.question[
How do I interpret $\widehat{\beta}_0 = 77.66$?
]
]

---

### Interpretation

.large[
\begin{align}
Score_{ij} &= \beta_0 + \beta_1 \text{SomeFlipped}_i + \beta_2 \text{FullyFlipped}_i + u_i + \varepsilon_{ij}
\end{align}

$\varepsilon_{ij} \overset{iid}{\sim} N(0, \sigma_\varepsilon^2) \hspace{1cm} u_i \overset{iid}{\sim} N(0, \sigma_u^2)$
]

.large[
* $\widehat{\beta}_0 = 77.66$, $\hspace{1cm} \widehat{\beta}_1 = 11.07$, $\hspace{1cm} \widehat{\beta}_2 = 2.81$
* $\widehat{\sigma}_\varepsilon^2 = 4.25$, $\hspace{1cm} \widehat{\sigma}_u^2 = 21.37$

.question[
How do I interpret $\widehat{\beta}_1 = 11.07$ and $\widehat{\beta}_2 = 2.81$?
]
]

---

### Interpretation

.large[
\begin{align}
Score_{ij} &= \beta_0 + \beta_1 \text{SomeFlipped}_i + \beta_2 \text{FullyFlipped}_i + u_i + \varepsilon_{ij}
\end{align}

$\varepsilon_{ij} \overset{iid}{\sim} N(0, \sigma_\varepsilon^2) \hspace{1cm} u_i \overset{iid}{\sim} N(0, \sigma_u^2)$
]

.large[
* $\widehat{\beta}_0 = 77.66$, $\hspace{1cm} \widehat{\beta}_1 = 11.07$, $\hspace{1cm} \widehat{\beta}_2 = 2.81$
* $\widehat{\sigma}_\varepsilon^2 = 4.25$, $\hspace{1cm} \widehat{\sigma}_u^2 = 21.37$

.question[
How do I interpret $\widehat{\beta}_1 = 11.07$ and $\widehat{\beta}_2 = 2.81$?
]
]

.large[
We expect that, on average, scores in some-flipped classes are 11.07 points higher than for no-flipped classes.

We expect that, on average, scores in fully-flipped classes are 2.81 points higher than for no-flipped classes.
]

---

### Interpretation

.large[
\begin{align}
Score_{ij} &= \beta_0 + \beta_1 \text{SomeFlipped}_i + \beta_2 \text{FullyFlipped}_i + u_i + \varepsilon_{ij}
\end{align}

$\varepsilon_{ij} \overset{iid}{\sim} N(0, \sigma_\varepsilon^2) \hspace{1cm} u_i \overset{iid}{\sim} N(0, \sigma_u^2)$
]

.large[
* $\widehat{\beta}_0 = 77.66$, $\hspace{1cm} \widehat{\beta}_1 = 11.07$, $\hspace{1cm} \widehat{\beta}_2 = 2.81$
* $\widehat{\sigma}_\varepsilon^2 = 4.25$, $\hspace{1cm} \widehat{\sigma}_u^2 = 21.37$

.question[
How do I interpret $\hspace{1cm} \widehat{\sigma}_u^2 = 21.37$?
]
]

---

### Interpretation

.large[
\begin{align}
Score_{ij} &= \beta_0 + \beta_1 \text{SomeFlipped}_i + \beta_2 \text{FullyFlipped}_i + u_i + \varepsilon_{ij}
\end{align}

$\varepsilon_{ij} \overset{iid}{\sim} N(0, \sigma_\varepsilon^2) \hspace{1cm} u_i \overset{iid}{\sim} N(0, \sigma_u^2)$
]

.large[
* $\widehat{\beta}_0 = 77.66$, $\hspace{1cm} \widehat{\beta}_1 = 11.07$, $\hspace{1cm} \widehat{\beta}_2 = 2.81$
* $\widehat{\sigma}_\varepsilon^2 = 4.25$, $\hspace{1cm} \widehat{\sigma}_u^2 = 21.37$

.question[
How do I interpret $\hspace{1cm} \widehat{\sigma}_u^2 = 21.37$?
]
]

.large[
The average score varies from professor to professor by about 4.62 ( $= \sqrt{21.37}$ ) points
]

---

### Interpretation

.large[
\begin{align}
Score_{ij} &= \beta_0 + \beta_1 \text{SomeFlipped}_i + \beta_2 \text{FullyFlipped}_i + u_i + \varepsilon_{ij}
\end{align}

$\varepsilon_{ij} \overset{iid}{\sim} N(0, \sigma_\varepsilon^2) \hspace{1cm} u_i \overset{iid}{\sim} N(0, \sigma_u^2)$
]

.large[
* $\widehat{\beta}_0 = 77.66$, $\hspace{1cm} \widehat{\beta}_1 = 11.07$, $\hspace{1cm} \widehat{\beta}_2 = 2.81$
* $\widehat{\sigma}_\varepsilon^2 = 4.25$, $\hspace{1cm} \widehat{\sigma}_u^2 = 21.37$

.question[
How do I interpret $\widehat{\sigma}_\varepsilon^2 = 4.25$?
]
]

---

### Interpretation

.large[
\begin{align}
Score_{ij} &= \beta_0 + \beta_1 \text{SomeFlipped}_i + \beta_2 \text{FullyFlipped}_i + u_i + \varepsilon_{ij}
\end{align}

$\varepsilon_{ij} \overset{iid}{\sim} N(0, \sigma_\varepsilon^2) \hspace{1cm} u_i \overset{iid}{\sim} N(0, \sigma_u^2)$
]

.large[
* $\widehat{\beta}_0 = 77.66$, $\hspace{1cm} \widehat{\beta}_1 = 11.07$, $\hspace{1cm} \widehat{\beta}_2 = 2.81$
* $\widehat{\sigma}_\varepsilon^2 = 4.25$, $\hspace{1cm} \widehat{\sigma}_u^2 = 21.37$

.question[
How do I interpret $\widehat{\sigma}_\varepsilon^2 = 4.25$?
]
]

.large[
Within a class, students' scores vary by about  2.06 ( $= \sqrt{4.25}$ ) points
]

---

### Intra-class correlation

.pull-left[
```{r echo=F, message=F, warning=F, fig.width=7, fig.height=4, fig.align='center'}

library(latex2exp)

ann_text_1 <- data.frame(score = 80, professor = 5.5,
                         style = factor("no flip",
                                        levels = c("no flip", "some flip", "full flip")))

ann_text_2 <- data.frame(score = 80, professor = 5.5,
                         style = factor("some flip",
                                        levels = c("no flip", "some flip", "full flip")))

ann_text_3 <- data.frame(score = 80, professor = 5.5,
                         style = factor("full flip",
                                        levels = c("no flip", "some flip", "full flip")))

set.seed(3)

mean_scores <- c(84, 78, 76, 82, 83,
                     82, 80, 90, 91, 87,
                     79, 80, 83, 82, 85)

data.frame(professor = rep(1:15, each=25),
           style = factor(rep(c("no flip", "some flip", "full flip"),
                                 each=125),
                             levels = c("no flip", "some flip", "full flip"))) %>%
  mutate(score = rnorm(375, mean = mean_scores[professor], sd = 6),
         professor = rep(rep(1:5, each=25), 3)) %>%
  ggplot(aes(x = as.factor(professor), y = score)) +
  geom_boxplot(lwd=1) +
  facet_wrap(~style) +
  scale_y_continuous(breaks = c(80, 83, 87),
                     labels = c(TeX("$\\beta_0"),
                                TeX("$\\beta_0 + \\beta_2"),
                                TeX("$\\beta_0 + \\beta_1"))) +
  labs(x = "Professor", y = "Score") +
  theme_classic() +
  theme(text = element_text(size = 30),
        axis.text.x=element_blank(),
        axis.text.y = element_text(size=20)) +
  geom_segment(aes(x = 0.5, y = 80,
                   xend = 5.5, yend = 80),
               data = ann_text_1,
               lwd = 1, lty=3) +
  geom_segment(aes(x = 0.5, y = 87,
                   xend = 5.5, yend = 87),
               data = ann_text_2,
               lwd = 1, lty=3) +
  geom_segment(aes(x = 0.5, y = 83,
                   xend = 5.5, yend = 83),
               data = ann_text_3,
               lwd = 1, lty=3)
```

.large[
$\sigma_\varepsilon^2$ is large relative to $\sigma_u^2$
]
]

.pull-right[
```{r echo=F, message=F, warning=F, fig.width=7, fig.height=4, fig.align='center'}

ann_text_1 <- data.frame(score = 80, professor = 5.5,
                         style = factor("no flip",
                                        levels = c("no flip", "some flip", "full flip")))

ann_text_2 <- data.frame(score = 80, professor = 5.5,
                         style = factor("some flip",
                                        levels = c("no flip", "some flip", "full flip")))

ann_text_3 <- data.frame(score = 80, professor = 5.5,
                         style = factor("full flip",
                                        levels = c("no flip", "some flip", "full flip")))

set.seed(3)

mean_scores <- c(84, 78, 76, 82, 83,
                     82, 80, 90, 91, 87,
                     79, 80, 83, 82, 85)

diffs <- mean_scores - rep(c(80, 87, 83), each=5)

mean_scores <- rep(c(80, 87, 83), each=5) + 3*diffs

data.frame(professor = rep(1:15, each=25),
           style = factor(rep(c("no flip", "some flip", "full flip"),
                                 each=125),
                             levels = c("no flip", "some flip", "full flip"))) %>%
  mutate(score = rnorm(375, mean = mean_scores[professor], sd = 2),
         professor = rep(rep(1:5, each=25), 3)) %>%
  ggplot(aes(x = as.factor(professor), y = score)) +
  geom_boxplot(lwd=1) +
  facet_wrap(~style) +
  scale_y_continuous(breaks = c(80, 83, 87),
                     labels = c(TeX("$\\beta_0"),
                                TeX("$\\beta_0 + \\beta_2"),
                                TeX("$\\beta_0 + \\beta_1"))) +
  labs(x = "Professor", y = "Score") +
  theme_classic() +
  theme(text = element_text(size = 30),
        axis.text.x=element_blank(),
        axis.text.y = element_text(size=20)) +
  geom_segment(aes(x = 0.5, y = 80,
                   xend = 5.5, yend = 80),
               data = ann_text_1,
               lwd = 1, lty=3) +
  geom_segment(aes(x = 0.5, y = 87,
                   xend = 5.5, yend = 87),
               data = ann_text_2,
               lwd = 1, lty=3) +
  geom_segment(aes(x = 0.5, y = 83,
                   xend = 5.5, yend = 83),
               data = ann_text_3,
               lwd = 1, lty=3)
```

.large[
$\sigma_\varepsilon^2$ is small relative to $\sigma_u^2$
]
]

.large[
* Observations within a group are *more correlated* when $\sigma_\varepsilon^2$ is small relative to $\sigma_u^2$
* **Intra-class correlation:** $\rho_{group} = \dfrac{\sigma_u^2}{\sigma_u^2 + \sigma_\varepsilon^2} = \dfrac{\text{between group variance}}{\text{total variance}}$
]

---

### Intra-class correlation

.large[
\begin{align}
Score_{ij} &= \beta_0 + \beta_1 \text{SomeFlipped}_i + \beta_2 \text{FullyFlipped}_i + u_i + \varepsilon_{ij}
\end{align}

$\varepsilon_{ij} \overset{iid}{\sim} N(0, \sigma_\varepsilon^2) \hspace{1cm} u_i \overset{iid}{\sim} N(0, \sigma_u^2)$
]

.large[
* $\widehat{\beta}_0 = 77.66$, $\hspace{1cm} \widehat{\beta}_1 = 11.07$, $\hspace{1cm} \widehat{\beta}_2 = 2.81$
* $\widehat{\sigma}_\varepsilon^2 = 4.25$, $\hspace{1cm} \widehat{\sigma}_u^2 = 21.37$

$$\widehat{\rho}_{group} = \dfrac{21.37}{21.37 + 4.25} = 0.83$$
]

.large[
So 83% of the variation in student's scores can be explained by differences in average scores from class to class (after accounting for teaching style). That's huge!
]

---

### Class activity, Part II

.large[
[https://sta214-f22.github.io/class_activities/ca_lecture_26.html](https://sta214-f22.github.io/class_activities/ca_lecture_26.html)
]

---

### Class activity

.large[
.question[
Interpret the estimate fixed effect coefficients $\widehat{\beta}_0$ and $\widehat{\beta}_1$.
]
]

---

### Class activity

.large[
.question[
Interpret the estimate fixed effect coefficients $\widehat{\beta}_0$ and $\widehat{\beta}_1$.
]
]

.large[
On average (across neighborhoods), we expect that the price of rental with 0 overall satisfaction is $27.28.

For a fixed neighborhood, an increase of 1 point in overall satisfaction is associated with an increase of $14.81 in rental price.
]

---

### Class activity

.large[
.question[
Calculate and interpret the estimated intra-class correlation.
]
]

---

### Class activity

.large[
.question[
Calculate and interpret the estimated intra-class correlation.
]
]

.large[
$\widehat{\rho}_{group} = \dfrac{1048}{1048 + 6762} = 0.134$

About 13% of the variability in price can be explained by differences in the average price between neighborhoods (after accounting for overall satisfaction).
]