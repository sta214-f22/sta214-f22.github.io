---
title: "Lab 4 Solutions"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
earthquake <- read.csv("https://sta214-f22.github.io/labs/EarthquakeData.csv")
```

### Question 1 (3 pts)

```{r, fig.cap="Figure 1: Distribution of Damage in the earthquake data"}
earthquake %>%
  ggplot(aes(x = Damage)) +
  geom_bar() +
  theme_bw()
```

```{r}
earthquake %>%
  count(Damage) %>%
  knitr::kable(caption = "Distribution of Damage")
```

**Grading:** 1 pt for figure, 1 pt for table, 1 pt for caption

### Question 2 (2 pts)

```{r}
table(earthquake$Damage)/nrow(earthquake)
```

47% in moderate, 12% in none, 41% in severe

**Grading:** They don't need to use any particular method/code to arrive at this answer

### Question 3 (2 pts)

The natural choice would be None, but this is also the smallest category, so we will make Moderate the baseline.

```{r}
earthquake <- earthquake %>%
  mutate(Damge = factor(Damage, 
                        levels = c("moderate", "none", "severe")))
```

**Grading:** Lose 1 point if they choose None or Severe as the baseline. Lose 1 point if they don't explain their reasoning.

### Question 4 (2 pts)

```{r, include=F}
log_rr_plot <- function(data, num_bins, bin_method,
                         x, y, cat_num, cat_denom,
                         grouping = NULL, reg_formula = y ~ x){
  
  if(is.null(grouping)){
    dat <- data.frame(x = data[,x], 
                      y = data[,y],
                      group = 1)
  } else {
    dat <- data.frame(x = data[,x], 
                      y = data[,y],
                      group = data[,grouping])
  }
  
  dat <- dat %>%
    filter(y %in% c(cat_num, cat_denom)) %>%
    mutate(obs = ifelse(y == cat_num, 1, 0))
  
  
  if(bin_method == "equal_size"){
    logodds_table <- dat %>%
      slice_sample(n = nrow(dat), replace=F) %>%
      drop_na() %>%
      arrange(group, x) %>%
      group_by(group) %>%
      mutate(bin = rep(1:num_bins,
                       each=ceiling(n()/num_bins))[1:n()]) %>%
      group_by(bin, group) %>%
      summarize(mean_x = mean(x),
                prop = mean(c(obs, 0.5)),
                num_obs = n()) %>%
      ungroup() %>%
      mutate(logodds = log(prop/(1 - prop)))
  } else {
    logodds_table <- dat %>%
      slice_sample(n = nrow(dat), replace=F) %>%
      drop_na() %>%
      group_by(group) %>%
      mutate(bin = cut(x, 
                       breaks = num_bins,
                       labels = F)) %>%
      group_by(bin, group) %>%
      summarize(mean_x = mean(x),
                prop = mean(c(obs, 0.5)),
                num_obs = n()) %>%
      ungroup() %>%
      mutate(logodds = log(prop/(1 - prop)))
  }
  
  if(is.null(grouping)){
    logodds_table %>%
      ggplot(aes(x = mean_x,
                 y = logodds)) +
      geom_point(size=2.5) +
      geom_smooth(se=F, method="lm", formula = reg_formula) +
      theme_bw() +
      labs(x = x,
           y = paste("Log RR", cat_num, "vs.", cat_denom)) +
      theme(text = element_text(size=15))
  } else {
    logodds_table %>%
      ggplot(aes(x = mean_x,
                 y = logodds,
                 color = group,
                 shape = group)) +
      geom_point(size=2.5) +
      geom_smooth(se=F, method="lm", formula = reg_formula) +
      theme_bw() +
      labs(x = x,
           y = paste("Log RR", cat_num, "vs.", cat_denom),
           color = grouping,
           shape = grouping) +
      theme(text = element_text(size=15))
  }
  
}
```

```{r}
log_rr_plot(earthquake, 20, "equal_size", 
            x = "age", y = "Damage", 
            cat_num = "none", cat_denom = "moderate", 
            reg_formula = y ~ poly(x, 2))

log_rr_plot(earthquake, 20, "equal_size", 
            x = "age", y = "Damage", 
            cat_num = "severe", cat_denom = "moderate", 
            reg_formula = y ~ poly(x, 2))
```

**Grading:** 1 point per plot

### Question 5 (4 pts)

$$Y_i \sim Categorical(\pi_{i(Moderate)}, \pi_{i(None)}, \pi_{i(Severe)})$$

$$\log \left( \dfrac{\pi_{i(None)}}{\pi_{i(Moderate)}} \right) = \beta_{0(None)} + \beta_{1(None)} Age_i + \beta_{2(None)} Age_i^2$$

$$\log \left( \dfrac{\pi_{i(Severe)}}{\pi_{i(Moderate)}} \right) = \beta_{0(Severe)} + \beta_{1(Severe)} Age_i + \beta_{2(Severe)} Age_i^2$$

**Grading:** Lose 1 point for missing subscripts ($i$, $(None)$, etc.). Lose 1 point for missing step 1 (the Categorical distribution). Lose 1 point for not including both log relative risks. Lose 1 point for missing polynomial transformation on Age.

### Question 6 (3 pts)

```{r}
library(nnet)

m1 <- multinom(Damage ~ poly(age, 2, raw=T), data = earthquake)
summary(m1)
```


$$\log \left( \dfrac{\widehat{\pi}_{i(None)}}{\widehat{\pi}_{i(Moderate)}} \right) = -0.355 -0.081 Age_i + 0.00039 Age_i^2$$

$$\log \left( \dfrac{\widehat{\pi}_{i(Severe)}}{\widehat{\pi}_{i(Moderate)}} \right) = -0.32 + 0.012 Age_i -0.0001 Age_i^2$$

**Grading:** 1 pt for correct notation (hats, subscripts, etc). 1 pt for polynomial fit. 1 pt for correct coefficients.

### Question 7 (3 pts)

```{r}
predict(m1, newdata = data.frame(age = 10), type="probs")
```

The correct answer is 38% (slight rounding errors are ok). They can get this either from the fitted model in R, or by doing the math by hand. Doing the math by hand:

* The relative risks are $$\dfrac{\widehat{\pi}_{i(None)}}{\widehat{\pi}_{i(Moderate)}} = \exp \{-0.355 - 0.081 \cdot 10 + 0.000039 \cdot 100 \} = 0.313$$


$$\dfrac{\widehat{\pi}_{i(Severe)}}{\widehat{\pi}_{i(Moderate)}} = \exp \{-0.32 + 0.012 \cdot 10 - 0.0001 \cdot 100 \} = 0.811$$

* So, the estimated probability of Severe damage is 
$$\dfrac{0.811}{1 + 0.811 + 0.313} = 0.38$$

**Grading:** 1 pt for correct answer, 2 pts for showing work (either in R or by hand)

### Question 8 (2 pts)

```{r, include=F}
plot_probsMultinom <- function(model, data, xvar){
  probs <- fitted(model)
  levels <- colnames(probs)
  dat <- cbind(data.frame(x = data[,xvar]), probs) %>%
    pivot_longer(!x, names_to = "level", values_to = "Probability")
    
  dat %>%
    arrange(x) %>%
    ggplot(aes(x = x, y = Probability)) +
    geom_line(lwd = 1.2) +
    theme_bw() +
    labs(x = xvar) +
    facet_grid(level ~ .)
}
```

```{r}
plot_probsMultinom(m1, earthquake, "age")
```

The probability of moderate damage increases with age, until the very end when it decreases slightly. The probability of severe damage increases slightly, then decreases, as age increases. The probability of no damage decreases then increases.

**Grading:** 1 pt for plot, 1 pt for descriptions.


### Question 9 (3 pts)

```{r}
table("Prediction" = predict(m1), "Actual" = earthquake$Damage)
```

Accuracy: (90337 + 9534)/211774 = 0.47

Performance is good for the moderate class, terrible for none, and pretty bad for severe. Overall, we don't do very well at predicting damage.

**Grading:** 1 pt for table, 1 pt for accuracy, 1 pt for description of performance in each class.


### Question 10 (3 pts)

```{r}
log_rr_plot(earthquake, 20, "equal_size", 
            x = "age", y = "Damage", 
            cat_num = "none", cat_denom = "moderate", 
            grouping = "land_surface_condition",
            reg_formula = y ~ poly(x, 2))

log_rr_plot(earthquake, 20, "equal_size", 
            x = "age", y = "Damage", 
            cat_num = "severe", cat_denom = "moderate", 
            grouping = "land_surface_condition",
            reg_formula = y ~ poly(x, 2))
```

With nonlinear relationships, it is hard to assess whether an interaction is needed because it is hard to tell whether the curves are "parallel" or not.

**Grading:** 1 pt per plot, 1 pt for description.


### Question 11 (6 pts)

```{r}
# full model
m2 <- multinom(Damage ~ poly(age, 2, raw=T) + land_surface_condition,
               data = earthquake)
summary(m2)

m3 <- multinom(Damage ~ poly(age, 2, raw=T)*land_surface_condition,
               data = earthquake)
summary(m3)
```

We need to test all the interaction terms; with three levels for surface condition, and a quadratic polynomial on Age, that gives 4 coefficients for each relative risk, so 8 coefficients total.

$H_0: \beta_{5(None)} = \beta_{6(None)} = \beta_{7(None)} = \beta_{8(None)} = beta_{5(Severe)} = \beta_{6(Severe)} = \beta_{7(Severe)} = \beta_{8(Severe)} = 0$

$H_A:$ at least one of the coefficients in $H_0$ is not 0

Test statistic: $G = 395766.2 - 395744.3 = 21.9 \sim \chi^2_8$

p-value:

```{r}
pchisq(21.9, df=8, lower.tail=F)
```

There is strong evidence that the interaction term is needed.

**Grading:** 1 pt for the correct full model, 1 pt for the correct reduced model, 1 pt for the correct hypotheses, 1 pt for the test statistic, 1 pt for the p-value (using correct degrees of freedom), and 1 pt for conclusion.



### Question 12 (2 pts)

We use the model with the interaction term:

```{r}
table("Prediction" = predict(m3), "Actual" = earthquake$Damage)
```

Accuracy is pretty much unchanged (still about 47%), and we still do a bad job with None and Severe. So we haven't improved the model much.

**Grading:** 1 pt for confusion matrix, 1 pt for description.

### Question 13 (3 pts)

For the first type of random guessing, accuracy would be 1/3 (worse than our model), but we would do a better job with the None and Severe categories. For the second type of random guessing, accuracy would be about 47% (the frequency of Moderate damage), which is pretty equivalent to our model. 

**Grading:** 1 pt for each accuracy, 1 pt for description.